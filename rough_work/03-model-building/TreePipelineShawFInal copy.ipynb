{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import system libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import data cleaning libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "\n",
    "# Import machine learning libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "# Import data visualisation libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import warning libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set working directory\n",
    "# Set this to your own path\n",
    "os.chdir('/home/shaw/Documents/GitHub/crop-yield-estimate/')\n",
    "# Set this to your own path\n",
    "sys.path.insert(0, '/home/shaw/Documents/GitHub/crop-yield-estimate/pipeline')\n",
    "\n",
    "# Import preprocessing libraries\n",
    "from preprocessing import clustering\n",
    "from preprocessing import dim_reduction\n",
    "from preprocessing import feature_selection\n",
    "from preprocessing import scaling\n",
    "from preprocessing import feature_engineering\n",
    "from preprocessing import cleaning\n",
    "\n",
    "# Preprocess data\n",
    "train_path = \"data/Train.csv\"\n",
    "test_path = \"data/Test.csv\"\n",
    "df = cleaning.clean_data(train_path, test_path)\n",
    "df = feature_engineering.get_features(df)\n",
    "df = scaling.scale_features(df)\n",
    "df = feature_selection.select_features(df)\n",
    "df = dim_reduction.reduce_dim(df)\n",
    "df = clustering.get_clusters(df)\n",
    "\n",
    "\n",
    "# Split data into training and test sets\n",
    "df_train = df[df['Yield'].isna() == False]\n",
    "df_test = df[df['Yield'].isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cols = ['SeedlingsPerPit','Ganaura','CropOrgFYM','NoFertilizerAppln','BasalDAP',\n",
    "            'BasalUrea','2appDaysUrea','Harv_hand_rent','Residue_length',\n",
    "            'TransplantingIrrigationHours_per_Acre','TransIrriCost_per_Acre',\n",
    "            'CropOrgFYM_per_Acre','BasalDAP_per_Acre','BasalUrea_per_Acre','1tdUrea_per_Acre',\n",
    "            'Harv_hand_rent_per_Acre','TpIrrigationCost_Imputed_per_Acre',\n",
    "            'Days_bw_SowTransp_Harv','Days_bw_Harv_Thresh','NursingDate_ModeDiff',\n",
    "            'TillageDate_ModeDiff','HarvestDate_ModeDiff','ThreshingDate_ModeDiff',\n",
    "            'Num_LandPrepMethod','Num_CropbasalFerts','Num_TopDressFert','Latitude',\n",
    "            'Longitude','CropEstMethod_LineSowingAfterTillage','Threshing_method_machine',\n",
    "            'Stubble_use_plowed_in_soil','LandPrepMethod_FourWheelTracRotavator_True',\n",
    "            'LandPrepMethod_WetTillagePuddling_True','NursDetFactor_PreMonsoonShowers_True',\n",
    "            'NursDetFactor_LabourAvailability_True','FirstTopDressFert_DAP_True',\n",
    "            'HarvestMonth_November','ThreshingMonth_January','Block_Chehrakala',\n",
    "            'PCropSolidOrgFertAppMethod_Broadcasting','PCropSolidOrgFertAppMethod_SoilApplied',\n",
    "            'MineralFertAppMethod_1_Broadcasting','MineralFertAppMethod_1_SoilApplied','PC4',\n",
    "            'PC10','PC21','top_shapley_k2_label_1', 'TpIrrigationHours_Imputed',\n",
    "            'TpIrrigationCost_Imputed', 'SeedlingsPerPit_Imputed', 'NursingDate_ModeDiff_Imputed',\n",
    "            '2appDaysUrea_Imputed']#,'Error_Prediction','Block_Prediction']#,'Linear_Yield_Prediction']\n",
    "\n",
    "# Remove the specified columns from top_cols\n",
    "columns_to_remove = ['SeedlingsPerPit', 'TransplantingIrrigationHours', 'TransIrriCost', 'StandingWater',\n",
    "                     '1appDaysUrea', '2appDaysUrea', 'TransplantingIrrigationHours_per_Acre',\n",
    "                     'TransIrriCost_per_Acre', 'TransplantingIrrigationHours_per_Acre_capped',\n",
    "                     'TransIrriCost_per_Acre_capped', 'Days_bw_Nurs_SowTransp', 'Days_bw_Nurs_Harv',\n",
    "                     'Days_bw_Nurs_Till', 'NursingDate_ModeDiff', 'Days_bw_Nurs_SowTransp_ModeDiff',\n",
    "                     'Days_bw_Nurs_Harv_ModeDiff', 'Days_bw_Nurs_Till_ModeDiff', '2appDaysUrea_MeanDiff']\n",
    "\n",
    "for column in columns_to_remove:\n",
    "    if column in top_cols:\n",
    "     top_cols.remove(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "---Predictions made---\n",
      "Model Worse than previous model\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shaw/Documents/GitHub/crop-yield-estimate/rough_work/03-model-building/TreePipelineShawFInal copy.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shaw/Documents/GitHub/crop-yield-estimate/rough_work/03-model-building/TreePipelineShawFInal%20copy.ipynb#W2sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shaw/Documents/GitHub/crop-yield-estimate/rough_work/03-model-building/TreePipelineShawFInal%20copy.ipynb#W2sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFold \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shaw/Documents/GitHub/crop-yield-estimate/rough_work/03-model-building/TreePipelineShawFInal%20copy.ipynb#W2sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m voting_regressor\u001b[39m.\u001b[39;49mfit(X_tr, y_tr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shaw/Documents/GitHub/crop-yield-estimate/rough_work/03-model-building/TreePipelineShawFInal%20copy.ipynb#W2sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shaw/Documents/GitHub/crop-yield-estimate/rough_work/03-model-building/TreePipelineShawFInal%20copy.ipynb#W2sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m test_predictors \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39mdrop(outcome_cols, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[top_cols]\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:605\u001b[0m, in \u001b[0;36mVotingRegressor.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the estimators.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \n\u001b[1;32m    585\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    604\u001b[0m y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 605\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/sklearn/ensemble/_voting.py:81\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators):\n\u001b[1;32m     76\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\u001b[39m}\u001b[39;00m\u001b[39m weights, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators)\u001b[39m}\u001b[39;00m\u001b[39m estimators\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[0;32m---> 81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m     82\u001b[0m     delayed(_fit_single_estimator)(\n\u001b[1;32m     83\u001b[0m         clone(clf),\n\u001b[1;32m     84\u001b[0m         X,\n\u001b[1;32m     85\u001b[0m         y,\n\u001b[1;32m     86\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m     87\u001b[0m         message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mVoting\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     88\u001b[0m         message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(names[idx], idx \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, \u001b[39mlen\u001b[39;49m(clfs)),\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m     \u001b[39mfor\u001b[39;49;00m idx, clf \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(clfs)\n\u001b[1;32m     91\u001b[0m     \u001b[39mif\u001b[39;49;00m clf \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdrop\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     92\u001b[0m )\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_estimators_ \u001b[39m=\u001b[39m Bunch()\n\u001b[1;32m     96\u001b[0m \u001b[39m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/sklearn/ensemble/_base.py:36\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m---> 36\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/catboost/core.py:5703\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5700\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5701\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5703\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[1;32m   5704\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[1;32m   5705\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[1;32m   5706\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/catboost/core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2320\u001b[0m         train_pool,\n\u001b[1;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2322\u001b[0m         params,\n\u001b[1;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2325\u001b[0m     )\n\u001b[1;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/catboost/core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import SVC\n",
    "import shap\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "from joblib import dump\n",
    "\n",
    "# Split data\n",
    "outcome_cols = [\"Yield\", \"Yield_per_Acre\", \"New_Yield\", \"New_Yield_per_Acre\"]\n",
    "\n",
    "X, y = df_train.drop(outcome_cols, axis=1), df_train[\"New_Yield_per_Acre\"]\n",
    "X = X[top_cols]\n",
    "\n",
    "# Initialise array to store sum of positive differences\n",
    "sum_of_positive_difference_list = [9156, 9147]\n",
    "\n",
    "for i in range(1, 100):\n",
    "    # Initialize an array to store fold-wise predictions\n",
    "    k = 5\n",
    "    fold_wise_predictions = np.zeros((len(df_test), k))\n",
    "\n",
    "    # Define number of splits for k-fold cross-validation\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Iterate over each fold and train XGBoost model\n",
    "    for i, (train_idx, val_idx) in enumerate(kfold.split(X)):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        # Instantiate an XGBoost regressor model\n",
    "        best_params = {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100,\n",
    "                       'alpha': 0, 'lambda': 0}\n",
    "        xgb_reg = xgb.XGBRegressor(**best_params, colsample_bytree=0.3, verbose=False)\n",
    "\n",
    "        # Tuned Tree estimators\n",
    "        lgbm = LGBMRegressor(boosting_type='goss', n_estimators=1000,\n",
    "                             learning_rate=0.08, num_leaves=100, max_depth=7, verbose=-1)\n",
    "        catboost = CatBoostRegressor(\n",
    "            depth=10, iterations=1000, learning_rate=0.5, l2_leaf_reg=5, verbose=False)\n",
    "\n",
    "        # Define the VotingRegressor\n",
    "        voting_regressor = VotingRegressor(\n",
    "            estimators=[\n",
    "                ('lgbm', lgbm),\n",
    "                ('catboost', catboost),\n",
    "                ('xgboost', xgb_reg)\n",
    "            ], weights=[2, 3, 1]\n",
    "        )\n",
    "\n",
    "        # Fit the model\n",
    "        print(f\"Fold {i+1}\")\n",
    "        voting_regressor.fit(X_tr, y_tr)\n",
    "\n",
    "        # Make predictions\n",
    "        test_predictors = df_test.drop(outcome_cols, axis=1)[top_cols]\n",
    "        test_folds_pred = voting_regressor.predict(\n",
    "            test_predictors) * df_test[\"Acre\"]\n",
    "\n",
    "        # Store fold-wise predictions\n",
    "        fold_wise_predictions[:, i] = test_folds_pred\n",
    "\n",
    "    # Calculate the average of predictions from each fold for each row\n",
    "    final_predictions = np.mean(fold_wise_predictions, axis=1)\n",
    "\n",
    "    # Add predictions to sample submission file\n",
    "    df_test_pred = pd.read_csv(\"data/SampleSubmission.csv\")\n",
    "    df_test_pred['Yield'] = final_predictions\n",
    "    df_test_pred['Yield'] = np.where(df_test_pred['ID'] == 'ID_PMSOXFT4FYDW',\n",
    "                                     df_test_pred['Yield'] * 10, df_test_pred['Yield'])\n",
    "\n",
    "    # Choose a floor value\n",
    "    df_test_pred['Yield'] = np.where(\n",
    "        df_test_pred['Yield'] <= 4, 4, df_test_pred['Yield'])\n",
    "\n",
    "    # Export submission\n",
    "    df_test_pred.to_csv('submission/SubmissionShawFinalRepeatTest.csv', index=False)\n",
    "\n",
    "    print(\"---Predictions made---\")\n",
    "\n",
    "    SubmissionShawFinalRepeatTest = pd.read_csv(\n",
    "        'submission/SubmissionShawFinalRepeatTest.csv')\n",
    "    SubmissionShawFinal = pd.read_csv('submission/SubmissionShawFinal.csv')\n",
    "\n",
    "    difference = (SubmissionShawFinal['Yield']).subtract(\n",
    "        SubmissionShawFinalRepeatTest['Yield'])\n",
    "    positive_difference = difference.abs()\n",
    "    sum_of_positive_difference = positive_difference.sum().sum()\n",
    "\n",
    "    if sum_of_positive_difference in sum_of_positive_difference_list:\n",
    "        print(\"Model already saved\")\n",
    "    elif sum_of_positive_difference < sum_of_positive_difference_list[-1]:\n",
    "        dump(voting_regressor, f'voting_regressor_model_{sum_of_positive_difference}.pkl')\n",
    "        sum_of_positive_difference_list.append(sum_of_positive_difference)\n",
    "    elif sum_of_positive_difference > sum_of_positive_difference_list[-1]:\n",
    "        print(\"Model Worse than previous model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
